{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catdog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wnBos-jDAM8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65d2ece-f949-4589-9bdd-5847656a0587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/files/datasets/data')\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKPyJzDiAjAV",
        "outputId": "dcb751bb-bf49-4e4d-aa96-9eac992bcb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "qgU-_HBUCO52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9vN80HHHC6Vs",
        "outputId": "11f6f4b8-c5eb-4ee9-cccd-b33cda99548d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/files/datasets/data/train'\n",
        "test_path = '/content/drive/MyDrive/files/datasets/data/test'\n",
        "valid_path = '/content/drive/MyDrive/files/datasets/data/valid'"
      ],
      "metadata": {
        "id": "MEMpHVJPH-wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 Data Preprocessing\n",
        "1. preprocessing training set\n",
        "2. preprocessing test set"
      ],
      "metadata": {
        "id": "-XgPZX9oDNkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    train_path, \n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7b9DUHVC9_1",
        "outputId": "43fa3453-4d34-409a-c4df-967102761047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")             # test_datagen does not need transformation to avoid leakage\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary' \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia5lghJLJkpk",
        "outputId": "ee74650d-0f5f-4f38-ea13-a0e00b8ba3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build a cnn"
      ],
      "metadata": {
        "id": "K7vSbDITjQPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n"
      ],
      "metadata": {
        "id": "TZvBp1JCjZev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn = Sequential([\n",
        "#             Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(64,64,3)),\n",
        "#             MaxPool2D(pool_size=(2,2), strides=2),\n",
        "#             Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "#             MaxPool2D(pool_size=64, strides=2),\n",
        "#             Flatten(),\n",
        "#             Dense(units=2, activation='softmax')\n",
        "# ])\n",
        "\n",
        "cnn = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "           padding='same', input_shape=(64, 64, 3)),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Flatten(),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "-i6a__5DlXMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VLmWyCenomt",
        "outputId": "569f4585-87e5-4e65-aa6d-ee4309dcc0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               2097280   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,116,801\n",
            "Trainable params: 2,116,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics =['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "QI4QbfQNqQBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x=training_set, validation_data=test_set, epochs=25, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG49lXsmq5BF",
        "outputId": "8d4bfa02-5982-485d-94cf-abdb0aebc362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "32/32 - 226s - loss: 0.7405 - accuracy: 0.5380 - val_loss: 0.6963 - val_accuracy: 0.5000 - 226s/epoch - 7s/step\n",
            "Epoch 2/25\n",
            "32/32 - 6s - loss: 0.6838 - accuracy: 0.5450 - val_loss: 0.6939 - val_accuracy: 0.5600 - 6s/epoch - 196ms/step\n",
            "Epoch 3/25\n",
            "32/32 - 6s - loss: 0.6744 - accuracy: 0.5960 - val_loss: 0.6608 - val_accuracy: 0.6300 - 6s/epoch - 196ms/step\n",
            "Epoch 4/25\n",
            "32/32 - 6s - loss: 0.6369 - accuracy: 0.6540 - val_loss: 0.6380 - val_accuracy: 0.6800 - 6s/epoch - 196ms/step\n",
            "Epoch 5/25\n",
            "32/32 - 6s - loss: 0.6254 - accuracy: 0.6540 - val_loss: 0.5860 - val_accuracy: 0.7300 - 6s/epoch - 193ms/step\n",
            "Epoch 6/25\n",
            "32/32 - 6s - loss: 0.6096 - accuracy: 0.6440 - val_loss: 0.5908 - val_accuracy: 0.6900 - 6s/epoch - 196ms/step\n",
            "Epoch 7/25\n",
            "32/32 - 6s - loss: 0.5973 - accuracy: 0.6910 - val_loss: 0.5732 - val_accuracy: 0.6900 - 6s/epoch - 195ms/step\n",
            "Epoch 8/25\n",
            "32/32 - 6s - loss: 0.5487 - accuracy: 0.7300 - val_loss: 0.5675 - val_accuracy: 0.7200 - 6s/epoch - 194ms/step\n",
            "Epoch 9/25\n",
            "32/32 - 6s - loss: 0.5401 - accuracy: 0.7270 - val_loss: 0.5646 - val_accuracy: 0.7700 - 6s/epoch - 192ms/step\n",
            "Epoch 10/25\n",
            "32/32 - 6s - loss: 0.5371 - accuracy: 0.7210 - val_loss: 0.6645 - val_accuracy: 0.6700 - 6s/epoch - 195ms/step\n",
            "Epoch 11/25\n",
            "32/32 - 6s - loss: 0.5251 - accuracy: 0.7480 - val_loss: 0.7528 - val_accuracy: 0.5900 - 6s/epoch - 194ms/step\n",
            "Epoch 12/25\n",
            "32/32 - 6s - loss: 0.5245 - accuracy: 0.7410 - val_loss: 0.5554 - val_accuracy: 0.7400 - 6s/epoch - 192ms/step\n",
            "Epoch 13/25\n",
            "32/32 - 6s - loss: 0.5062 - accuracy: 0.7530 - val_loss: 0.5906 - val_accuracy: 0.7200 - 6s/epoch - 194ms/step\n",
            "Epoch 14/25\n",
            "32/32 - 6s - loss: 0.5212 - accuracy: 0.7380 - val_loss: 0.5453 - val_accuracy: 0.7600 - 6s/epoch - 195ms/step\n",
            "Epoch 15/25\n",
            "32/32 - 6s - loss: 0.4690 - accuracy: 0.7740 - val_loss: 0.5712 - val_accuracy: 0.7500 - 6s/epoch - 192ms/step\n",
            "Epoch 16/25\n",
            "32/32 - 6s - loss: 0.4458 - accuracy: 0.8000 - val_loss: 0.5990 - val_accuracy: 0.7300 - 6s/epoch - 192ms/step\n",
            "Epoch 17/25\n",
            "32/32 - 6s - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.6098 - val_accuracy: 0.6500 - 6s/epoch - 192ms/step\n",
            "Epoch 18/25\n",
            "32/32 - 6s - loss: 0.4761 - accuracy: 0.7630 - val_loss: 0.6172 - val_accuracy: 0.7300 - 6s/epoch - 195ms/step\n",
            "Epoch 19/25\n",
            "32/32 - 6s - loss: 0.4355 - accuracy: 0.7780 - val_loss: 0.6213 - val_accuracy: 0.7400 - 6s/epoch - 190ms/step\n",
            "Epoch 20/25\n",
            "32/32 - 6s - loss: 0.4203 - accuracy: 0.7970 - val_loss: 0.6449 - val_accuracy: 0.7000 - 6s/epoch - 190ms/step\n",
            "Epoch 21/25\n",
            "32/32 - 6s - loss: 0.3935 - accuracy: 0.7990 - val_loss: 0.7313 - val_accuracy: 0.6900 - 6s/epoch - 191ms/step\n",
            "Epoch 22/25\n",
            "32/32 - 6s - loss: 0.3794 - accuracy: 0.8200 - val_loss: 0.5794 - val_accuracy: 0.7300 - 6s/epoch - 191ms/step\n",
            "Epoch 23/25\n",
            "32/32 - 6s - loss: 0.3707 - accuracy: 0.8430 - val_loss: 0.6000 - val_accuracy: 0.7200 - 6s/epoch - 195ms/step\n",
            "Epoch 24/25\n",
            "32/32 - 6s - loss: 0.3567 - accuracy: 0.8500 - val_loss: 0.6004 - val_accuracy: 0.7300 - 6s/epoch - 194ms/step\n",
            "Epoch 25/25\n",
            "32/32 - 6s - loss: 0.3333 - accuracy: 0.8580 - val_loss: 0.6610 - val_accuracy: 0.7100 - 6s/epoch - 193ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca6a672410>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/files/datasets/data/valid/dog/dog.10021.jpg', target_size=(64,64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)"
      ],
      "metadata": {
        "id": "6fw8PjMOuJoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = test_image/255"
      ],
      "metadata": {
        "id": "M-Xk0jALyERS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] > 0.5:\n",
        "  prediction = \"dog\"\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "\n",
        "print(prediction)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S3BXVFmyb98",
        "outputId": "282eadba-6fdd-484d-e973-3544e10702a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n",
            "[[0.9998728]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "id": "DaLcp5251Ap1",
        "outputId": "9b2cd8e4-927f-41a2-92f5-cd64f8df5dee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 0, 'dog': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}